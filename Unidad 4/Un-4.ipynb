{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Aprendizaje supervisado\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 1: Regresión Líneal\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de regresión lineal consiste en identificar con precisión una línea que sea capaz de representar la distribución de puntos en un plano bidimensional. Dada la siguiente ecuación de la recta:\n",
    "y=  (y_2-y_1)/(x_2-x_1 )*(x-x_1 )+y_(1 =)  (y_2-y_1)/(x_2-x_1 )*x+(y_(1 )-(y_2-y_1)/(x_2-x_1 )*x_1 )\n",
    "\n",
    "y=α*x+β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat_csv  = pd.read_csv('datos4.csv', encoding = \"ISO-8859-1\")\n",
    "datos_x = dat_csv.x\n",
    "datos_y = dat_csv.y\n",
    "x = []\n",
    "y = []\n",
    "for i in dat_csv.x:\n",
    "    x.append(i)\n",
    "for j in dat_csv.y:\n",
    "    y.append(j)\n",
    "print(x)    \n",
    "print(y)\n",
    "\n",
    "X = np.array(x)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0342bf4ad6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 2: Creamos datos de entrenamiento\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento = int(0.8 * len(X))\n",
    "datos_entrenamiento\n",
    "datos_prueba = len(X) - datos_entrenamiento\n",
    "datos_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y\n",
    "datos_entrenamiento = int(0.8 * len(X))\n",
    "datos_prueba = len(X) - datos_entrenamiento\n",
    " \n",
    "#ENTRENAMIENTO\n",
    "X_entrenamiento = X[:datos_entrenamiento].reshape((datos_entrenamiento,1))\n",
    "print(X_entrenamiento)\n",
    "Y_entrenamiento = Y[:datos_entrenamiento].reshape((datos_entrenamiento,1))\n",
    "print(Y_entrenamiento)\n",
    "#PRUEBA\n",
    "X_prueba = X[datos_entrenamiento:].reshape((datos_prueba,1))\n",
    "Y_prueba = Y[datos_entrenamiento:].reshape((datos_prueba,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 3 - Realizamos regresión lineal.\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Creamos un objeto de regresión lineal\n",
    "linear_regressor = linear_model.LinearRegression()     \n",
    "\n",
    "# Ajustamos la regresión a los datos de entrenamiento\n",
    "linear_regressor.fit(X_entrenamiento, Y_entrenamiento)\n",
    "\n",
    "# Y a partir de datos de regresión encontrados\n",
    "Y_predicha_de_entrenamiento = linear_regressor.predict(X_entrenamiento)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_entrenamiento, Y_entrenamiento, color='red')\n",
    "plt.plot(X_entrenamiento, Y_predicha_de_entrenamiento, color='black', linewidth=2)\n",
    "plt.title('Datos de entrenamiento')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Una vez que visualizamos el ajuste podemos evaluar la correspondencia de la regresión con relación a los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicha_de_prueba = linear_regressor.predict(X_prueba)\n",
    "plt.figure()\n",
    "plt.scatter(X_prueba, Y_prueba, color='red')\n",
    "plt.plot(X_prueba, Y_predicha_de_prueba, color='black', linewidth=2)\n",
    "plt.title('Datos de prueba')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias formas de evaluar una regresión lineal, y podemos utilizar nuevamente scikit-learn  para realizar esta tarea, mediante el módulo metrics según se muestra a continuación:   \n",
    ">•\t__Error absoluto medio:__ este es el promedio de errores absolutos de todos los puntos de datos en el conjunto de datos dado.\n",
    "\n",
    ">•\t__Error cuadrático medio:__ Este es el promedio de los cuadrados de los errores de todos los puntos de datos en el conjunto de datos dado. ¡Es una de las métricas más populares que hay!\n",
    "\n",
    ">•\t__Error absoluto mediano:__ Esta es la mediana de todos los errores en el conjunto de datos dado. La principal ventaja de esta métrica es que es robusta a los valores atípicos. Un único punto negativo en el conjunto de datos de prueba no distorsionaría la métrica de error completa, en lugar de una métrica de error promedio.\n",
    "\n",
    ">•\t__Puntuación de varianza explicada:__ esta puntuación mide qué tan bien nuestro modelo puede explicar la variación en nuestro conjunto de datos. Una puntuación de 1.0 indica que nuestro modelo es perfecto.\n",
    "\n",
    ">•\t__Puntuación R2:__ Se nombra como R cuadrado, y esta puntuación se refiere al coeficiente de determinación. Esto nos dice qué tan bien serán predichas las muestras desconocidas por nuestro modelo. La mejor puntuación posible es 1.0, pero la puntuación también puede ser negativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "print(\"Error absoluto medio =\", round(sm.mean_absolute_error(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Error cuadratico medio =\", round(sm.mean_squared_error(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Error absoluto mediano =\", round(sm.median_absolute_error(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Puntuación de varianza explicada =\", round(sm.explained_variance_score(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Puntuación R2 =\", round(sm.r2_score(Y_prueba, Y_predicha_de_prueba), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión contraída\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permite eliminar puntos aislados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regresion_ridge = linear_model.Ridge(alpha=0.01, fit_intercept=True, max_iter=10000)\n",
    "regresion_ridge.fit(X_prueba, Y_prueba)\n",
    "\n",
    "Y_predicha_de_prueba = regresion_ridge.predict(X_prueba)\n",
    "\n",
    "\n",
    "print(\"Error absoluto medio =\", round(sm.mean_absolute_error(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Error cuadratico medio =\", round(sm.mean_squared_error(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Error absoluto mediano =\", round(sm.median_absolute_error(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Puntuación de varianza explicada =\", round(sm.explained_variance_score(Y_prueba, Y_predicha_de_prueba), 2)) \n",
    "print(\"Puntuación R2 =\", round(sm.r2_score(Y_prueba, Y_predicha_de_prueba), 2))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_prueba, Y_prueba, color='red')\n",
    "plt.plot(X_prueba, Y_predicha_de_prueba, color='black', linewidth=2)\n",
    "plt.title('Datos de prueba')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Clasificación - Regresión logística.\n",
    "==\n",
    "La regresión logística (Logistic Regression), a pesar de su nombre, es un modelo lineal para la clasificación en lugar de la regresión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1\n",
    "==\n",
    "Comencemos por tomar una serie de puntos según se muestra a continuación y graficarlos como hemos aprendido a hacer hasta aquí.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[16,2], [3,1], [2,7], [13,4], [3,4], [12,5], [15,6], [4,6]])\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2\n",
    "==\n",
    "Dados los puntos de dispersión parecen existir dos grupos de datos, uno que se agrupa en torno al valor x = 3 y otro que se agrupa en torno al valor x = 14, lo que haremos es en base a esta hipótesis asignar a los valores cercanos a 3 el valor de cero y a los cercanos a catorce el valor de uno y agregaremos los valores en el mismo orden dentro del array Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [1, 0, 0, 1, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3\n",
    "==\n",
    "Ahora utilizaremos el objeto clasificador “LogisticRegresion” y le pasaremos los datos que deseamos clasificar de forma de crear un modelo, haciendo que se ajuste mediante el uso de (fit)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = linear_model.LogisticRegression(solver='lbfgs', C=100)\n",
    "clasificador.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4\n",
    "==\n",
    "Con la clasificación realizada, utilizaremos el método predict() de forma de predecir como el modelo predice los propios valores pasados como datos. Este es un caso muy simple en el cual la predicción retorna exactamente los mismos valores, sin embargo en otros casos más complejos el ajuste no es del 100% y el modelo debe ser ajustado a medida que conocemos más la problemática del tema tratado. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = clasificador.predict(X)\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clasificador.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 5\n",
    "==\n",
    "Ahora en base a otros datos recopilados podemos ver como el modelo predice al grupo al cual deberían pertenecer los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = np.array([[6,4], [20,7], [4,17]])\n",
    "Yn = clasificador.predict(Xn)\n",
    "print(Yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 6\n",
    "==\n",
    "Siempre es mejor tratar de visualizar los datos para tener una mejor comprensión del tema, por lo que vamos a graficar los datos asignando como colores las opciones de ceros o unos de la clasificación (c=Y). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.concatenate((X, Xn), axis=0)\n",
    "Ys = np.append(Y , Yn)\n",
    "\n",
    "x_min, x_max = min(Xs[:, 0]) - 1.0, max(Xs[:, 0]) + 1.0\n",
    "y_min, y_max = min(Xs[:, 1]) - 1.0, max(Xs[:, 1]) + 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado ahora los puntos de los ejes x e y crearemos a partir de ellos una malla de puntos lo cual es en la practica una cuadricula rectangular creada a partir de los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.01\n",
    "\n",
    "valor_x, valor_y = np.meshgrid(np.arange(x_min, x_max, step_size), np.arange(y_min, y_max, step_size))\n",
    " \n",
    "malla_de_puntos = clasificador.predict(np.c_[valor_x.ravel(), valor_y.ravel()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí estamos utilizando el método ravel() de forma de crear una copia de los valores originales. También podríamos haber utilizado el método flatten(), la diferencia entre ambos son: \n",
    ">__ravel ():__ Retorna una referencia a la matriz original, si se modifica la matriz, el valor de la matriz original también cambia. ravel() es más rápido que flatten().\n",
    "\n",
    ">__flatten ():__ Retorna una copia de la matriz original, si sei modifica algún valor de esta matriz, el valor de la matriz original no se verá afectado.  \n",
    "\n",
    "Tambien notar que estamos utilizando np.c_, para obtener los datos por pares x, y ya que dada una matriz  nos retorna sus valores por columnas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 7 \n",
    "==\n",
    "Creamos un mapa de color a partir de los datos anteriores mediante pcolormesh() :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malla_de_puntos = malla_de_puntos.reshape(valor_x.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(valor_x, valor_y, malla_de_puntos, cmap=plt.cm.gray, shading='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 8\n",
    "==\n",
    "Finalmente podemos poner sobre un gráfico todos los puntos tanto los de entrenamiento como los de testeo y comprobar que el modelo a separado correctamente los valores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malla_de_puntos = malla_de_puntos.reshape(valor_x.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(valor_x, valor_y, malla_de_puntos, cmap=plt.cm.gray, shading='auto')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=80, edgecolors='red', linewidth=1, cmap=plt.cm.Paired)\n",
    "plt.scatter(Xn[:, 0], Xn[:, 1], c=clasificador.predict(Xn), s=180, edgecolors='blue', linewidth=2, cmap=plt.cm.Paired)\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJEMPLO RESHAPE()\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 5, 10])\n",
    "y = np.array([1, 4, 8])\n",
    "z = np.linspace(0, 255, 9).reshape(3, 3)\n",
    "print(z)\n",
    "plt.pcolormesh(x, y, z, cmap = \"PuRd\", shading ='auto'); #cmap = \"PuRd\");\n",
    "plt.colorbar();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
